{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import breizhcrops as bzh\n",
    "from breizhcrops import BreizhCrops\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, f1_score, recall_score, precision_score\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "frh01 = BreizhCrops(\"frh01\")\n",
    "frh02 = BreizhCrops(\"frh02\")\n",
    "frh03 = BreizhCrops(\"frh03\")\n",
    "frh04 = BreizhCrops(\"frh04\")\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "frh01.domain = 1\n",
    "frh02.domain = 2\n",
    "frh03.domain = 3\n",
    "frh04.domain = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset, X=0.8):\n",
    "    \n",
    "    total_samples = len(dataset)\n",
    "\n",
    "    num_test_samples = int(X * total_samples)\n",
    "\n",
    "    np.random.seed(42)\n",
    "\n",
    "    test_indices = np.random.choice(total_samples, num_test_samples, replace=False)\n",
    "\n",
    "    # Find complementary indices\n",
    "    train_indices = np.setdiff1d(np.arange(total_samples), test_indices)\n",
    "\n",
    "    test = torch.utils.data.Subset(dataset, test_indices)\n",
    "    train = torch.utils.data.Subset(dataset, train_indices)\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(batchsize=32, X=0.8, num_workers=0, upperPerformance=False):\n",
    "\n",
    "    frh01_train, frh01_test = split_dataset(frh01, X=X)\n",
    "\n",
    "    if upperPerformance:\n",
    "        traindatasets = frh01_train\n",
    "    else:\n",
    "        traindatasets = torch.utils.data.ConcatDataset([frh02, frh03, frh04])\n",
    "\n",
    "    testdataset = frh01_test\n",
    "    \n",
    "  \n",
    "    \n",
    "\n",
    "    traindataloader = DataLoader(traindatasets, batch_size=batchsize, shuffle=True, num_workers=num_workers)\n",
    "    testdataloader = DataLoader(testdataset, batch_size=batchsize, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "    meta = dict(\n",
    "        ndims=13,\n",
    "        num_classes=frh02.classes,\n",
    "        sequencelength=45\n",
    "    )\n",
    "\n",
    "    return traindataloader, testdataloader, meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, test_dataloader, meta = get_dataloader(batchsize=32, num_workers=0, X=0.2, upperPerformance=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13809, 1040)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader), len(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Model(torch.nn.Module):\n",
    "    def __init__(self, input_size=13, hidden_size=128, num_layers=4, output_size=9, bidirectional=False, dropout=0.2, c_norm=True):\n",
    "        super(LSTM_Model, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.output_size = output_size\n",
    "        self.c_norm = c_norm\n",
    "        \n",
    "        if num_layers > 1 and dropout > 0:\n",
    "            self.dropout = dropout\n",
    "        else:\n",
    "            self.dropout = 0.0 \n",
    "            \n",
    "        self.clayernorm = nn.LayerNorm((hidden_size + hidden_size * bidirectional) * num_layers)\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers,\n",
    "                            bias=False, batch_first=True, dropout=dropout, bidirectional=bidirectional)   \n",
    "        \n",
    "        if bidirectional:\n",
    "            hidden_size = hidden_size * 2\n",
    "             \n",
    "        self.fc = nn.Linear(hidden_size * num_layers, output_size, bias=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        outputs, last_state_list = self.lstm.forward(x)\n",
    "\n",
    "        h, c = last_state_list\n",
    "\n",
    "        nlayers, batchsize, n_hidden = c.shape\n",
    "        \n",
    "        if self.c_norm:\n",
    "            x = self.clayernorm(c.transpose(0, 1).contiguous().view(batchsize, nlayers * n_hidden))\n",
    "        else:\n",
    "            x = c.transpose(0, 1).contiguous().view(batchsize, nlayers * n_hidden)\n",
    "        x = self.fc.forward(x)\n",
    "        return x\n",
    "        \n",
    "    def save(self, path=\"model.pth\", **kwargs):\n",
    "        print(\"\\nsaving model to \" + path)\n",
    "        model_state = self.state_dict()\n",
    "        os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "        torch.save(dict(model_state=model_state, **kwargs), path)\n",
    "        \n",
    "model = LSTM_Model(input_size=13, hidden_size=128, num_layers=4, output_size=9, bidirectional=False, dropout=0.2, c_norm=True).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    kappa = cohen_kappa_score(y_true, y_pred)\n",
    "    f1_micro = f1_score(y_true, y_pred, average=\"micro\")\n",
    "    f1_macro = f1_score(y_true, y_pred, average=\"macro\")\n",
    "    f1_weighted = f1_score(y_true, y_pred, average=\"weighted\")\n",
    "    recall_micro = recall_score(y_true, y_pred, average=\"micro\")\n",
    "    recall_macro = recall_score(y_true, y_pred, average=\"macro\")\n",
    "    recall_weighted = recall_score(y_true, y_pred, average=\"weighted\")\n",
    "    precision_micro = precision_score(y_true, y_pred, average=\"micro\")\n",
    "    precision_macro = precision_score(y_true, y_pred, average=\"macro\")\n",
    "    precision_weighted = precision_score(y_true, y_pred, average=\"weighted\")\n",
    "\n",
    "    return dict(\n",
    "        accuracy=accuracy,\n",
    "        kappa=kappa,\n",
    "        f1_micro=f1_micro,\n",
    "        f1_macro=f1_macro,\n",
    "        f1_weighted=f1_weighted,\n",
    "        recall_micro=recall_micro,\n",
    "        recall_macro=recall_macro,\n",
    "        recall_weighted=recall_weighted,\n",
    "        precision_micro=precision_micro,\n",
    "        precision_macro=precision_macro,\n",
    "        precision_weighted=precision_weighted,\n",
    "    )\n",
    "\n",
    "\n",
    "def train_epoch(model, optimizer, criterion, dataloader, device):\n",
    "    model.train()\n",
    "    losses = list()\n",
    "    with tqdm(enumerate(dataloader), total=len(dataloader), leave=True) as iterator:\n",
    "        for idx, batch in iterator:\n",
    "            optimizer.zero_grad()\n",
    "            x, y_true, _ , _= batch\n",
    "            loss = criterion(model.forward(x.to(device)), y_true.to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            iterator.set_description(f\"train loss={loss:.2f}\")\n",
    "            losses.append(loss)\n",
    "    return torch.stack(losses)\n",
    "\n",
    "\n",
    "def test_epoch(model, criterion, dataloader, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        losses = list()\n",
    "        y_true_list = list()\n",
    "        y_pred_list = list()\n",
    "        field_ids_list = list()\n",
    "        with tqdm(enumerate(dataloader), total=len(dataloader), leave=True) as iterator:\n",
    "            for idx, batch in iterator:\n",
    "                x, y_true, field_id, _ = batch\n",
    "                logits = model.forward(x.to(device))\n",
    "                loss = criterion(logits, y_true.to(device))\n",
    "                iterator.set_description(f\"test loss={loss:.2f}\")\n",
    "                losses.append(loss)\n",
    "                y_true_list.append(y_true)\n",
    "                y_pred_list.append(logits.argmax(-1))\n",
    "                field_ids_list.append(field_id)\n",
    "        return torch.stack(losses), torch.cat(y_true_list), torch.cat(y_pred_list), torch.cat(field_ids_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lower Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X=0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataloader.dataset), len(test_dataloader.dataset)\n",
    "len_train = len(train_dataloader)\n",
    "n_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999449286177706"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = len_train; epoch = 20\n",
    "p = float(idx + epoch * len_train) / n_epochs / len_train\n",
    "alpha = 2. / (1. + np.exp(-10 * p)) - 1\n",
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15177 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m log \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m----> 8\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     test_loss, y_true, y_pred, \u001b[38;5;241m*\u001b[39m_ \u001b[38;5;241m=\u001b[39m test_epoch(model, criterion, test_dataloader, device)\n\u001b[1;32m     10\u001b[0m     scores1 \u001b[38;5;241m=\u001b[39m metrics(y_true\u001b[38;5;241m.\u001b[39mcpu(), y_pred\u001b[38;5;241m.\u001b[39mcpu())\n",
      "Cell \u001b[0;32mIn[26], line 33\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, optimizer, criterion, dataloader, device)\u001b[0m\n\u001b[1;32m     31\u001b[0m losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m()\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(dataloader), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(dataloader), leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m iterator:\n\u001b[0;32m---> 33\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_env/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_env/lib/python3.12/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_env/lib/python3.12/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_env/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_env/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:277\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    217\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_env/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:144\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    141\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_env/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:152\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    149\u001b[0m             \u001b[38;5;66;03m# The sequence type may not support `__init__(iterable)` (e.g., `range`).\u001b[39;00m\n\u001b[1;32m    150\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]\n\u001b[0;32m--> 152\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[38;5;241m.\u001b[39mformat(elem_type))\n",
      "\u001b[0;31mTypeError\u001b[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "model = LSTM_Model(input_size=13, hidden_size=64, num_layers=2, output_size=9, bidirectional=False, dropout=0.2, c_norm=True).to(device)\n",
    "train_dataloader, test_dataloader, meta = get_dataloader(batchsize=32, num_workers=0, X=0.8, upperPerformance=False)\n",
    "criterion = torch.nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "optimizer = Adam(model.parameters(), 0.005, weight_decay=1e-6)\n",
    "log = list()\n",
    "for epoch in range(10):\n",
    "    train_loss = train_epoch(model, optimizer, criterion, train_dataloader, device)\n",
    "    test_loss, y_true, y_pred, *_ = test_epoch(model, criterion, test_dataloader, device)\n",
    "    scores1 = metrics(y_true.cpu(), y_pred.cpu())\n",
    "    scores_msg = \", \".join([f\"{k}={v:.2f}\" for (k, v) in scores1.items()])\n",
    "    test_loss = test_loss.cpu().detach().numpy()[0]\n",
    "    train_loss = train_loss.cpu().detach().numpy()[0]\n",
    "    print(f\"epoch {epoch}: trainloss {train_loss:.2f}, testloss {test_loss:.2f} \" + scores_msg)\n",
    "\n",
    "    scores1[\"epoch\"] = epoch\n",
    "    scores1[\"trainloss\"] = train_loss\n",
    "    scores1[\"testloss\"] = test_loss\n",
    "    log.append(scores1)\n",
    "\n",
    "    log_df = pd.DataFrame(log).set_index(\"epoch\")\n",
    "    log_df.to_csv(\"Lower_08.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "model = LSTM_Model(input_size=13, hidden_size=64, num_layers=2, output_size=9, bidirectional=False, dropout=0.2, c_norm=True).to(device)\n",
    "train_dataloader, test_dataloader, meta = get_dataloader(batchsize=32, num_workers=0, X=0.6, upperPerformance=False)\n",
    "criterion = torch.nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "optimizer = Adam(model.parameters(), 0.005, weight_decay=1e-6)\n",
    "log = list()\n",
    "for epoch in range(10):\n",
    "    train_loss = train_epoch(model, optimizer, criterion, train_dataloader, device)\n",
    "    test_loss, y_true, y_pred, *_ = test_epoch(model, criterion, test_dataloader, device)\n",
    "    scores1 = metrics(y_true.cpu(), y_pred.cpu())\n",
    "    scores_msg = \", \".join([f\"{k}={v:.2f}\" for (k, v) in scores1.items()])\n",
    "    test_loss = test_loss.cpu().detach().numpy()[0]\n",
    "    train_loss = train_loss.cpu().detach().numpy()[0]\n",
    "    print(f\"epoch {epoch}: trainloss {train_loss:.2f}, testloss {test_loss:.2f} \" + scores_msg)\n",
    "\n",
    "    scores1[\"epoch\"] = epoch\n",
    "    scores1[\"trainloss\"] = train_loss\n",
    "    scores1[\"testloss\"] = test_loss\n",
    "    log.append(scores1)\n",
    "\n",
    "    log_df = pd.DataFrame(log).set_index(\"epoch\")\n",
    "    log_df.to_csv(\"Lower_06.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "model = LSTM_Model(input_size=13, hidden_size=64, num_layers=2, output_size=9, bidirectional=False, dropout=0.2, c_norm=True).to(device)\n",
    "train_dataloader, test_dataloader, meta = get_dataloader(batchsize=32, num_workers=0, X=0.4, upperPerformance=False)\n",
    "criterion = torch.nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "optimizer = Adam(model.parameters(), 0.005, weight_decay=1e-6)\n",
    "log = list()\n",
    "for epoch in range(10):\n",
    "    train_loss = train_epoch(model, optimizer, criterion, train_dataloader, device)\n",
    "    test_loss, y_true, y_pred, *_ = test_epoch(model, criterion, test_dataloader, device)\n",
    "    scores1 = metrics(y_true.cpu(), y_pred.cpu())\n",
    "    scores_msg = \", \".join([f\"{k}={v:.2f}\" for (k, v) in scores1.items()])\n",
    "    test_loss = test_loss.cpu().detach().numpy()[0]\n",
    "    train_loss = train_loss.cpu().detach().numpy()[0]\n",
    "    print(f\"epoch {epoch}: trainloss {train_loss:.2f}, testloss {test_loss:.2f} \" + scores_msg)\n",
    "\n",
    "    scores1[\"epoch\"] = epoch\n",
    "    scores1[\"trainloss\"] = train_loss\n",
    "    scores1[\"testloss\"] = test_loss\n",
    "    log.append(scores1)\n",
    "\n",
    "    log_df = pd.DataFrame(log).set_index(\"epoch\")\n",
    "    log_df.to_csv(\"Lower_04.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/13427 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m log \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m----> 8\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     test_loss, y_true, y_pred, \u001b[38;5;241m*\u001b[39m_ \u001b[38;5;241m=\u001b[39m test_epoch(model, criterion, test_dataloader, device)\n\u001b[1;32m     10\u001b[0m     scores1 \u001b[38;5;241m=\u001b[39m metrics(y_true\u001b[38;5;241m.\u001b[39mcpu(), y_pred\u001b[38;5;241m.\u001b[39mcpu())\n",
      "Cell \u001b[0;32mIn[8], line 33\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, optimizer, criterion, dataloader, device)\u001b[0m\n\u001b[1;32m     31\u001b[0m losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m()\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(dataloader), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(dataloader), leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m iterator:\n\u001b[0;32m---> 33\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_env/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_env/lib/python3.12/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_env/lib/python3.12/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_env/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_env/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:277\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    217\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_env/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:144\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    141\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_env/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:152\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    149\u001b[0m             \u001b[38;5;66;03m# The sequence type may not support `__init__(iterable)` (e.g., `range`).\u001b[39;00m\n\u001b[1;32m    150\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]\n\u001b[0;32m--> 152\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[38;5;241m.\u001b[39mformat(elem_type))\n",
      "\u001b[0;31mTypeError\u001b[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "model = LSTM_Model(input_size=13, hidden_size=64, num_layers=2, output_size=9, bidirectional=False, dropout=0.2, c_norm=True).to(device)\n",
    "train_dataloader, test_dataloader, meta = get_dataloader(batchsize=32, num_workers=0, X=0.2, upperPerformance=False)\n",
    "criterion = torch.nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "optimizer = Adam(model.parameters(), 0.005, weight_decay=1e-6)\n",
    "log = list()\n",
    "for epoch in range(10):\n",
    "    train_loss = train_epoch(model, optimizer, criterion, train_dataloader, device)\n",
    "    test_loss, y_true, y_pred, *_ = test_epoch(model, criterion, test_dataloader, device)\n",
    "    scores1 = metrics(y_true.cpu(), y_pred.cpu())\n",
    "    scores_msg = \", \".join([f\"{k}={v:.2f}\" for (k, v) in scores1.items()])\n",
    "    test_loss = test_loss.cpu().detach().numpy()[0]\n",
    "    train_loss = train_loss.cpu().detach().numpy()[0]\n",
    "    print(f\"epoch {epoch}: trainloss {train_loss:.2f}, testloss {test_loss:.2f} \" + scores_msg)\n",
    "\n",
    "    scores1[\"epoch\"] = epoch\n",
    "    scores1[\"trainloss\"] = train_loss\n",
    "    scores1[\"testloss\"] = test_loss\n",
    "    log.append(scores1)\n",
    "\n",
    "    log_df = pd.DataFrame(log).set_index(\"epoch\")\n",
    "    log_df.to_csv(\"Lower_02.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upper Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "model = LSTM_Model(input_size=13, hidden_size=64, num_layers=2, output_size=9, bidirectional=False, dropout=0.2, c_norm=True).to(device)\n",
    "train_dataloader, test_dataloader, meta = get_dataloader(batchsize=32, num_workers=0, X=0.8, upperPerformance=True)\n",
    "criterion = torch.nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "optimizer = Adam(model.parameters(), 0.005, weight_decay=1e-6)\n",
    "log = list()\n",
    "for epoch in range(10):\n",
    "    train_loss = train_epoch(model, optimizer, criterion, train_dataloader, device)\n",
    "    test_loss, y_true, y_pred, *_ = test_epoch(model, criterion, test_dataloader, device)\n",
    "    scores1 = metrics(y_true.cpu(), y_pred.cpu())\n",
    "    scores_msg = \", \".join([f\"{k}={v:.2f}\" for (k, v) in scores1.items()])\n",
    "    test_loss = test_loss.cpu().detach().numpy()[0]\n",
    "    train_loss = train_loss.cpu().detach().numpy()[0]\n",
    "    print(f\"epoch {epoch}: trainloss {train_loss:.2f}, testloss {test_loss:.2f} \" + scores_msg)\n",
    "\n",
    "    scores1[\"epoch\"] = epoch\n",
    "    scores1[\"trainloss\"] = train_loss\n",
    "    scores1[\"testloss\"] = test_loss\n",
    "    log.append(scores1)\n",
    "\n",
    "    log_df = pd.DataFrame(log).set_index(\"epoch\")\n",
    "    log_df.to_csv(\"Upper_08.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "model = LSTM_Model(input_size=13, hidden_size=64, num_layers=2, output_size=9, bidirectional=False, dropout=0.2, c_norm=True).to(device)\n",
    "train_dataloader, test_dataloader, meta = get_dataloader(batchsize=32, num_workers=0, X=0.6, upperPerformance=True)\n",
    "criterion = torch.nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "optimizer = Adam(model.parameters(), 0.005, weight_decay=1e-6)\n",
    "log = list()\n",
    "for epoch in range(10):\n",
    "    train_loss = train_epoch(model, optimizer, criterion, train_dataloader, device)\n",
    "    test_loss, y_true, y_pred, *_ = test_epoch(model, criterion, test_dataloader, device)\n",
    "    scores1 = metrics(y_true.cpu(), y_pred.cpu())\n",
    "    scores_msg = \", \".join([f\"{k}={v:.2f}\" for (k, v) in scores1.items()])\n",
    "    test_loss = test_loss.cpu().detach().numpy()[0]\n",
    "    train_loss = train_loss.cpu().detach().numpy()[0]\n",
    "    print(f\"epoch {epoch}: trainloss {train_loss:.2f}, testloss {test_loss:.2f} \" + scores_msg)\n",
    "\n",
    "    scores1[\"epoch\"] = epoch\n",
    "    scores1[\"trainloss\"] = train_loss\n",
    "    scores1[\"testloss\"] = test_loss\n",
    "    log.append(scores1)\n",
    "\n",
    "    log_df = pd.DataFrame(log).set_index(\"epoch\")\n",
    "    log_df.to_csv(\"Upper_06.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_dataloader() missing 1 required positional argument: 'mode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmps\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mmps\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m LSTM_Model(input_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m13\u001b[39m, hidden_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, num_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, output_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m9\u001b[39m, bidirectional\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, c_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 3\u001b[0m train_dataloader, test_dataloader, meta \u001b[38;5;241m=\u001b[39m \u001b[43mget_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatchsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupperPerformance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m criterion \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss(reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m Adam(model\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m0.005\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-6\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: get_dataloader() missing 1 required positional argument: 'mode'"
     ]
    }
   ],
   "source": [
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "model = LSTM_Model(input_size=13, hidden_size=64, num_layers=2, output_size=9, bidirectional=False, dropout=0.2, c_norm=True).to(device)\n",
    "train_dataloader, test_dataloader, meta = get_dataloader(batchsize=32, num_workers=0, X=0.4, upperPerformance=True)\n",
    "criterion = torch.nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "optimizer = Adam(model.parameters(), 0.005, weight_decay=1e-6)\n",
    "log = list()\n",
    "for epoch in range(10):\n",
    "    train_loss = train_epoch(model, optimizer, criterion, train_dataloader, device)\n",
    "    test_loss, y_true, y_pred, *_ = test_epoch(model, criterion, test_dataloader, device)\n",
    "    scores1 = metrics(y_true.cpu(), y_pred.cpu())\n",
    "    scores_msg = \", \".join([f\"{k}={v:.2f}\" for (k, v) in scores1.items()])\n",
    "    test_loss = test_loss.cpu().detach().numpy()[0]\n",
    "    train_loss = train_loss.cpu().detach().numpy()[0]\n",
    "    print(f\"epoch {epoch}: trainloss {train_loss:.2f}, testloss {test_loss:.2f} \" + scores_msg)\n",
    "\n",
    "    scores1[\"epoch\"] = epoch\n",
    "    scores1[\"trainloss\"] = train_loss\n",
    "    scores1[\"testloss\"] = test_loss\n",
    "    log.append(scores1)\n",
    "\n",
    "    log_df = pd.DataFrame(log).set_index(\"epoch\")\n",
    "    log_df.to_csv(\"Upper_04.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4466 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss=0.80: 100%|██████████| 4466/4466 [04:25<00:00, 16.80it/s]\n",
      "test loss=1.38: 100%|██████████| 1117/1117 [01:14<00:00, 15.06it/s]\n",
      "/Users/aliyilmaz/anaconda3/envs/pytorch_env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/aliyilmaz/anaconda3/envs/pytorch_env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: trainloss 2.37, testloss 0.47 accuracy=0.74, kappa=0.66, f1_micro=0.74, f1_macro=0.47, f1_weighted=0.71, recall_micro=0.74, recall_macro=0.48, recall_weighted=0.74, precision_micro=0.74, precision_macro=0.49, precision_weighted=0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss=0.68: 100%|██████████| 4466/4466 [04:39<00:00, 15.95it/s]\n",
      "test loss=0.79: 100%|██████████| 1117/1117 [00:50<00:00, 22.06it/s]\n",
      "/Users/aliyilmaz/anaconda3/envs/pytorch_env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/aliyilmaz/anaconda3/envs/pytorch_env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: trainloss 0.56, testloss 0.38 accuracy=0.77, kappa=0.71, f1_micro=0.77, f1_macro=0.52, f1_weighted=0.76, recall_micro=0.77, recall_macro=0.52, recall_weighted=0.77, precision_micro=0.77, precision_macro=0.52, precision_weighted=0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss=0.46: 100%|██████████| 4466/4466 [04:27<00:00, 16.68it/s]\n",
      "test loss=0.77: 100%|██████████| 1117/1117 [01:05<00:00, 17.00it/s]\n",
      "/Users/aliyilmaz/anaconda3/envs/pytorch_env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/aliyilmaz/anaconda3/envs/pytorch_env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2: trainloss 0.45, testloss 0.38 accuracy=0.78, kappa=0.71, f1_micro=0.78, f1_macro=0.54, f1_weighted=0.77, recall_micro=0.78, recall_macro=0.53, recall_weighted=0.78, precision_micro=0.78, precision_macro=0.54, precision_weighted=0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss=0.43: 100%|██████████| 4466/4466 [05:31<00:00, 13.48it/s]\n",
      "test loss=0.92: 100%|██████████| 1117/1117 [01:25<00:00, 13.00it/s]\n",
      "/Users/aliyilmaz/anaconda3/envs/pytorch_env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/aliyilmaz/anaconda3/envs/pytorch_env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3: trainloss 0.52, testloss 0.43 accuracy=0.79, kappa=0.73, f1_micro=0.79, f1_macro=0.54, f1_weighted=0.79, recall_micro=0.79, recall_macro=0.54, recall_weighted=0.79, precision_micro=0.79, precision_macro=0.55, precision_weighted=0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss=0.46: 100%|██████████| 4466/4466 [06:23<00:00, 11.64it/s]\n",
      "test loss=0.68: 100%|██████████| 1117/1117 [01:30<00:00, 12.40it/s]\n",
      "/Users/aliyilmaz/anaconda3/envs/pytorch_env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/aliyilmaz/anaconda3/envs/pytorch_env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4: trainloss 0.26, testloss 0.32 accuracy=0.80, kappa=0.74, f1_micro=0.80, f1_macro=0.55, f1_weighted=0.79, recall_micro=0.80, recall_macro=0.54, recall_weighted=0.80, precision_micro=0.80, precision_macro=0.55, precision_weighted=0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss=0.28: 100%|██████████| 4466/4466 [06:09<00:00, 12.08it/s]\n",
      "test loss=0.79: 100%|██████████| 1117/1117 [01:27<00:00, 12.74it/s]\n",
      "/Users/aliyilmaz/anaconda3/envs/pytorch_env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/aliyilmaz/anaconda3/envs/pytorch_env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5: trainloss 0.43, testloss 0.31 accuracy=0.79, kappa=0.73, f1_micro=0.79, f1_macro=0.53, f1_weighted=0.76, recall_micro=0.79, recall_macro=0.54, recall_weighted=0.79, precision_micro=0.79, precision_macro=0.55, precision_weighted=0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss=0.64: 100%|██████████| 4466/4466 [06:19<00:00, 11.76it/s]\n",
      "test loss=1.12: 100%|██████████| 1117/1117 [01:38<00:00, 11.36it/s]\n",
      "/Users/aliyilmaz/anaconda3/envs/pytorch_env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/aliyilmaz/anaconda3/envs/pytorch_env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6: trainloss 0.68, testloss 0.45 accuracy=0.80, kappa=0.74, f1_micro=0.80, f1_macro=0.54, f1_weighted=0.79, recall_micro=0.80, recall_macro=0.54, recall_weighted=0.80, precision_micro=0.80, precision_macro=0.55, precision_weighted=0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss=0.49: 100%|██████████| 4466/4466 [06:40<00:00, 11.16it/s]\n",
      "test loss=0.71: 100%|██████████| 1117/1117 [01:27<00:00, 12.74it/s]\n",
      "/Users/aliyilmaz/anaconda3/envs/pytorch_env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/aliyilmaz/anaconda3/envs/pytorch_env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7: trainloss 0.31, testloss 0.36 accuracy=0.79, kappa=0.74, f1_micro=0.79, f1_macro=0.55, f1_weighted=0.80, recall_micro=0.79, recall_macro=0.55, recall_weighted=0.79, precision_micro=0.79, precision_macro=0.55, precision_weighted=0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss=1.04: 100%|██████████| 4466/4466 [05:51<00:00, 12.71it/s]\n",
      "test loss=0.98: 100%|██████████| 1117/1117 [01:17<00:00, 14.49it/s]\n",
      "/Users/aliyilmaz/anaconda3/envs/pytorch_env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/aliyilmaz/anaconda3/envs/pytorch_env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8: trainloss 0.43, testloss 0.40 accuracy=0.80, kappa=0.74, f1_micro=0.80, f1_macro=0.55, f1_weighted=0.79, recall_micro=0.80, recall_macro=0.54, recall_weighted=0.80, precision_micro=0.80, precision_macro=0.56, precision_weighted=0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train loss=0.51: 100%|██████████| 4466/4466 [05:55<00:00, 12.55it/s]\n",
      "test loss=0.84: 100%|██████████| 1117/1117 [01:19<00:00, 14.02it/s]\n",
      "/Users/aliyilmaz/anaconda3/envs/pytorch_env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9: trainloss 0.45, testloss 0.29 accuracy=0.81, kappa=0.76, f1_micro=0.81, f1_macro=0.56, f1_weighted=0.81, recall_micro=0.81, recall_macro=0.56, recall_weighted=0.81, precision_micro=0.81, precision_macro=0.56, precision_weighted=0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aliyilmaz/anaconda3/envs/pytorch_env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "model = LSTM_Model(input_size=13, hidden_size=64, num_layers=2, output_size=9, bidirectional=False, dropout=0.2, c_norm=True).to(device)\n",
    "train_dataloader, test_dataloader, meta = get_dataloader(batchsize=32, num_workers=0, X=0.2, upperPerformance=True)\n",
    "criterion = torch.nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "optimizer = Adam(model.parameters(), 0.005, weight_decay=1e-6)\n",
    "log = list()\n",
    "for epoch in range(10):\n",
    "    train_loss = train_epoch(model, optimizer, criterion, train_dataloader, device)\n",
    "    test_loss, y_true, y_pred, *_ = test_epoch(model, criterion, test_dataloader, device)\n",
    "    scores1 = metrics(y_true.cpu(), y_pred.cpu())\n",
    "    scores_msg = \", \".join([f\"{k}={v:.2f}\" for (k, v) in scores1.items()])\n",
    "    test_loss = test_loss.cpu().detach().numpy()[0]\n",
    "    train_loss = train_loss.cpu().detach().numpy()[0]\n",
    "    print(f\"epoch {epoch}: trainloss {train_loss:.2f}, testloss {test_loss:.2f} \" + scores_msg)\n",
    "\n",
    "    scores1[\"epoch\"] = epoch\n",
    "    scores1[\"trainloss\"] = train_loss\n",
    "    scores1[\"testloss\"] = test_loss\n",
    "    log.append(scores1)\n",
    "\n",
    "    log_df = pd.DataFrame(log).set_index(\"epoch\")\n",
    "    log_df.to_csv(\"Upper_02.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/13809 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m log \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m----> 8\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     test_loss, y_true, y_pred, \u001b[38;5;241m*\u001b[39m_ \u001b[38;5;241m=\u001b[39m test_epoch(model, criterion, test_dataloader, device)\n\u001b[1;32m     10\u001b[0m     scores1 \u001b[38;5;241m=\u001b[39m metrics(y_true\u001b[38;5;241m.\u001b[39mcpu(), y_pred\u001b[38;5;241m.\u001b[39mcpu())\n",
      "Cell \u001b[0;32mIn[33], line 33\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, optimizer, criterion, dataloader, device)\u001b[0m\n\u001b[1;32m     31\u001b[0m losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m()\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(dataloader), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(dataloader), leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m iterator:\n\u001b[0;32m---> 33\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_env/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_env/lib/python3.12/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_env/lib/python3.12/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_env/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_env/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:277\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    217\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_env/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:144\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    141\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_env/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:152\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    149\u001b[0m             \u001b[38;5;66;03m# The sequence type may not support `__init__(iterable)` (e.g., `range`).\u001b[39;00m\n\u001b[1;32m    150\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]\n\u001b[0;32m--> 152\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[38;5;241m.\u001b[39mformat(elem_type))\n",
      "\u001b[0;31mTypeError\u001b[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "model = LSTM_Model(input_size=13, hidden_size=64, num_layers=2, output_size=9, bidirectional=False, dropout=0.2, c_norm=True).to(device)\n",
    "train_dataloader, test_dataloader, meta = get_dataloader(batchsize=32, num_workers=0, X=0.2, upperPerformance=False, mode='124')\n",
    "criterion = torch.nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "optimizer = Adam(model.parameters(), 0.005, weight_decay=1e-6)\n",
    "log = list()\n",
    "for epoch in range(10):\n",
    "    train_loss = train_epoch(model, optimizer, criterion, train_dataloader, device)\n",
    "    test_loss, y_true, y_pred, *_ = test_epoch(model, criterion, test_dataloader, device)\n",
    "    scores1 = metrics(y_true.cpu(), y_pred.cpu())\n",
    "    scores_msg = \", \".join([f\"{k}={v:.2f}\" for (k, v) in scores1.items()])\n",
    "    test_loss = test_loss.cpu().detach().numpy()[0]\n",
    "    train_loss = train_loss.cpu().detach().numpy()[0]\n",
    "    print(f\"epoch {epoch}: trainloss {train_loss:.2f}, testloss {test_loss:.2f} \" + scores_msg)\n",
    "\n",
    "    scores1[\"epoch\"] = epoch\n",
    "    scores1[\"trainloss\"] = train_loss\n",
    "    scores1[\"testloss\"] = test_loss\n",
    "    log.append(scores1)\n",
    "\n",
    "    log_df = pd.DataFrame(log).set_index(\"epoch\")\n",
    "    log_df.to_csv(\"Upper_02.csv\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
